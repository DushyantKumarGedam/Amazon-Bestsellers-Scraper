
# ğŸ“¦ Amazon Bestsellers Scraper
### Scrape Bestselling Electronics from Amazon & Analyze the Data!

![Amazon Scraper Banner](https://user-images.githubusercontent.com/your_image.png)  
*(Replace with an actual image if needed)*

---

## ğŸš€ Features
âœ… Scrapes Amazon's Bestsellers (Electronics)  
âœ… Saves Data to CSV  
âœ… Cleans & Processes Data  
âœ… Generates Visualizations (Price & Ratings)  
âœ… Fully Automated â€“ Just Run & Get Insights!  

---

## ğŸ“‚ Folder Structure
```
amazon_scraper_project/
â”‚â”€â”€ data_scraping/
â”‚   â”œâ”€â”€ amazon.py               # Main script (scraping, cleaning, visualization)
â”‚   â”œâ”€â”€ requirements.txt        # Required Python libraries
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ amazon_bestsellers.csv  # Scraped product data (saved here)
â”‚â”€â”€ visualizations/
â”‚   â”œâ”€â”€ price_distribution.png  # Graphs saved here
â”‚   â”œâ”€â”€ rating_distribution.png
â”‚â”€â”€ url.txt                     # Stores Amazon URL
â”‚â”€â”€ README.md                    # Project documentation
```

---

## ğŸ›  Installation & Setup
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/amazon_scraper_project.git
cd amazon_scraper_project
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r data_scraping/requirements.txt
```

### 3ï¸âƒ£ Add an Amazon URL
Edit `url.txt` and add an Amazon Bestsellers URL (Example):
```
https://www.amazon.in/gp/bestsellers/electronics/
```

---

## â–¶ï¸ How to Run
Run the script with:
```bash
python3 data_scraping/amazon.py
```
âœ… This will:  
- Scrape Amazon's Bestsellers  
- Save data in `data/amazon_bestsellers.csv`  
- Generate **graphs** in `visualizations/`  

---

## ğŸ“Š Sample Output
- **Price Distribution**  
  ![Price Distribution Graph](https://user-images.githubusercontent.com/sample_price_graph.png) *(Replace with actual image)*  
- **Rating vs Price Scatter Plot**  
  ![Scatter Plot](https://user-images.githubusercontent.com/sample_scatter_plot.png)  

---

## ğŸ” How It Works
âœ” Reads the **Amazon URL** from `url.txt`  
âœ” **Sends a request** to Amazon (with headers to avoid blocks)  
âœ” **Extracts product details** (Title, Price, Rating)  
âœ” **Cleans & Processes Data**  
âœ” **Generates visualizations**  

---

## ğŸ’¡ Customization
### ğŸ–Š Modify the Categories
To scrape different categories, **update the URL** in `url.txt`:
```
https://www.amazon.in/gp/bestsellers/books/
```

### ğŸ“… Scrape Multiple Pages
Modify the script to loop through multiple pages:
```python
for page in range(1, 5):
    url = f"https://www.amazon.in/gp/bestsellers/electronics/?pg={page}"
```

---

## ğŸ“Œ Contributing
ğŸš€ Contributions are welcome! If you find a bug or want to add features:  
1. **Fork the repo**  
2. **Create a new branch** (`feature-new-idea`)  
3. **Commit & push**  
4. **Open a Pull Request**  

---

## ğŸ“œ License
This project is licensed under the **MIT License**. Feel free to use and modify it.  

---

## ğŸ’¬ Contact & Support
ğŸ“§ **Email:** your-email@example.com  
ğŸ™ **GitHub:** [@yourusername](https://github.com/yourusername)  

If you found this useful, **â­ Star the repo** and share! ğŸš€  

---

### ğŸ‰ Happy Scraping! ğŸš€
```

---

## **ğŸ“Œ How to Use This File**
1. **Copy** the above code.  
2. **Create a `README.md` file** in your GitHub repository:
   ```bash
   touch README.md
   ```
3. **Paste the content** inside `README.md`.  
4. **Commit & Push** to GitHub:
   ```bash
   git add README.md
   git commit -m "Added project documentation"
   git push origin main
   ```

Now, your repository is **ready for GitHub** and **easy to use for others! ğŸš€**